{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptrons and Backpropagation Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequesites\n",
    "![](data/nomenclature.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T3.1 Cost functions TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) What effect will the choice of error measure have on the predictor?    \n",
    "\n",
    "(b)  Give  examples  of  problems  in  which  each  of  the  measures  discussed  in  the  lecture,  i.e.linear, quadratic, maximum penaltyandtolerate small errors, will have an advantage overthe others?    \n",
    "\n",
    "(c)  If the output of a neural network is interpreted as the probability that the input blongs to oneclass, which error function could be suitable?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T3.2 Validation\n",
    "(a)  What is validation and why is it needed?    \n",
    "\n",
    "(b)  What is the differences betweenover-fittingandunder-fitting?   \n",
    "\n",
    "(c)  Name and discuss the techniques presented in the lecture to perform validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H3.1 Binary Classification\n",
    "### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H3.2 MLP Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load regression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(open('data/RegressionData.txt', 'rb'), delimiter=' ', skiprows=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5503 0.9206 0.5359 0.6081 0.0202 0.8545 0.2357 0.4847 0.3996 0.1957]\n",
      "[-0.5894 -0.2507 -0.0468 -0.3402  0.2857 -1.0683  0.8605 -0.0801  0.6837\n",
      "  1.185 ]\n"
     ]
    }
   ],
   "source": [
    "X = data[:,0]  # random numbers x_n drawn from uniform distribution over [0,1]\n",
    "print(X)\n",
    "Y = data[:,1]  # labels/target values t_n for x_n, generated using 2*pi*x_n, gaussian noise with standard deviation sigma=0.25\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = 10\n",
    "# a = 1 .. p\n",
    "# set weights\n",
    "# set biases (theta)\n",
    "# N^1 = 3 (hidden layer with 3 nodes)\n",
    "# single output neuron N^L = N^2 = 1 --> with random variables [-0.5,0.5]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
